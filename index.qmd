---
title: 'Reliable maintenance of machine learning models'
format:
  revealjs: 
    theme: [dark, custom.scss]
    footer: <https://juliasilge.github.io/ml-maintenance-2023>
    preview-links: auto
    width: 1280
    height: 720
    incremental: true
    code-line-numbers: false
    highlight-style: a11y-light
    title-slide-attributes: 
      data-background-image: images/end_paper.jpg
      data-background-opacity: "0.2"
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"
---

## Hello!

<center>

<img src="https://github.com/juliasilge.png" style="border-radius: 50%;" width="300px"/>

[{{< fa brands github >}} \@juliasilge](https://github.com/juliasilge)

[{{< fa brands mastodon >}} \@juliasilge\@fosstodon.org](https://fosstodon.org/@juliasilge)

[{{< fa brands youtube >}} youtube.com/juliasilge](https://www.youtube.com/juliasilge)

[{{< fa link >}} juliasilge.com](https://juliasilge.com/)

</center>

#  {background-image="images/mohammed-gadi-2qCX0SsSwzs-unsplash.jpg"}

:::footer
:::

# Maintaining ML models is NOTHING LIKE THIS  {background-image="images/mohammed-gadi-2qCX0SsSwzs-unsplash.jpg" background-opacity=0.2}

##  {background-image="images/image-from-rawpixel-id-8863371-original.jpg"}

:::footer
:::


::: {.notes}
Never-ending laundry process

We need to decide when and how to retrain model

We need to measure model performance
:::

# What does performance mean? {background-image="images/end_paper.jpg" background-opacity=0.2}

::: {.notes}
All software products need to be maintained, but models are both a software artifact *and* a statistical artifact

Unlike something that is "only" a software product, you could, say, retrain your model with new data and change its statistical properties without changing its software properties

Deciding when and how to retrain is part of this model maintenance process, and one of the most basic prerequisites for model maintenance is monitoring the model's performance
:::

## My model is performing well!

. . .

üë©üèº‚Äçüîß My model returns predictions quickly, doesn't use too much memory or processing power, and doesn't have outages.


. . .

::: {.callout-caution icon=false}

## Metrics

::: {.nonincremental}
- latency
- memory and CPU usage
- uptime
:::

:::

::: {.notes}
"We aren't even talking about the same thing"
:::

## My model is performing well! 

. . .

üë©üèΩ‚Äçüî¨ My model returns predictions that are close to the true values for the predicted quantity.

. . .

::: {.callout-caution icon=false}

## Metrics

::: {.nonincremental}
- accuracy
- ROC AUC
- F1 score
- RMSE
- log loss
:::

:::

::: {.notes}
As data practitioners, we focus on monitoring statistical performance
:::

# Failures in statistical performance can be *silent* {background-image="images/image-from-rawpixel-id-8863371-original.jpg" background-opacity=0.4}

::: {.notes}
How bad can this be? very bad
:::

# MODEL DRIFT {background-image="images/end_paper.jpg" background-opacity=0.2}

:::{.notes}
data drift vs. concept drift
:::

# DATA DRIFT {background-image="images/end_paper.jpg" background-opacity=0.2}

::: {.notes}
Let's say I run a laundry service, and I have built a model to predict someone's likelihood to become my customer

I use a bunch of predictors, like how many loads of laundry they need to do each month, their income, whether they live in a house or apartment, and a bunch of other things
:::

# Monitor your inputs {background-color="white"}

```{r}
#| echo: false
#| fig-align: center
library(tidymodels)
theme_set(silgelib::theme_roboto())
data(diamonds)
diamond_split <- initial_split(diamonds)
diamond_train <- training(diamond_split)
diamond_test <- testing(diamond_split)

p <- 
  diamond_test |> 
  filter(x > 0.5) |> 
  ggplot(aes(x)) +
  geom_density(adjust = 1.5, linewidth = 1.2, alpha = 0.4, fill = "#e7ad52", color = "#e7ad52") +
  labs(x = "one of your predictors")

p
```

# Monitor your inputs {background-color="white"}

```{r}
#| echo: false
#| fig-align: center
x_mean <- mean(diamond_train$x)
p + geom_vline(xintercept = x_mean, color = "#011520", linewidth = 1.5, lty = 2)
```

# Monitor your inputs {background-color="white"}

```{r}
#| echo: false
#| fig-align: center
p + geom_vline(xintercept = x_mean + 1.7, color = "#011520", linewidth = 1.5, lty = 2)
```

::: {.notes}
True/real changes in distribution vs. changes in data collection or similar
:::

# DATA DRIFT {background-image="images/end_paper.jpg" background-opacity=0.2}

Monitor your **inputs**


# CONCEPT DRIFT {background-image="images/end_paper.jpg" background-opacity=0.2}

. . .

Monitor your **outputs**

::: {.notes}
Relationship between the input and output is changing over time

In the city where I run a laundry service, the new apartments that are being built all have laundry in people's units
:::


## Monitor your outputs {background-color="white"}

```{r}
#| echo: false
data(two_class_example)
pretend_dates <- as.Date("2023-03-05") + 0:100
set.seed(2023)
laundry_service_monitoring <-
  as_tibble(two_class_example) |> 
  mutate(date = sample(pretend_dates, size = nrow(two_class_example), replace = TRUE)) |> 
  rename(.pred_customer = Class1, customer = truth, .pred = predicted) |> 
  arrange(date)
```


```{r}
library(vetiver)

laundry_service_monitoring |> 
  vetiver_compute_metrics(date, "week", customer, .pred)
```

## Monitor your outputs {background-color="white"}

```{r}
#| fig-align: center
#| output-location: fragment
library(vetiver)

laundry_service_monitoring |> 
  vetiver_compute_metrics(date, "week", customer, .pred) |> 
  vetiver_plot_metrics()
```

## Feedback loops üîÅ

Deployment of an ML model may *alter* the training data 

. . .

::: {.callout-caution icon=false}

## Examples

- Movie recommendation systems on Netflix, Disney+, Hulu
- Identifying fraudulent credit card transactions at Stripe
- Recidivism models

:::


::: footer
[*Building Machine Learning Pipelines* by Hapke & Nelson](https://www.oreilly.com/library/view/building-machine-learning/9781492053187/)
:::

::: {.notes}
Users take some action as a result of a prediction, users rate or correct the quality of a prediction, produce feedback automatically

Example with Chicago data
:::

# Stages of model monitoring maturity


1. Manual üôÇ

2. Reproducible ü§ì

3. Automated ü§©

::: footer
[5 Levels of MLOps Maturity](https://www.nannyml.com/blog/5-levels-of-mlops-maturity)
:::

## {background-color="white"}

![](images/dashboard1.png){fig-align="center"}

:::footer
:::

## {background-color="white"}

![](images/dashboard2.png){fig-align="center"}

:::footer
:::

## {background-color="white"}

![](images/dashboard3.png){fig-align="center"}

:::footer
:::

# Resilient models that are successful in the long term {background-image="images/end_paper.jpg" background-opacity=0.2}

::: {.notes}
We've talked about 

- understanding what performance means for models 
- measuring inputs and outputs
- how to consider both the software and statistical characteristics of a model

These are what you need to have a model that is easier to maintain
:::


## Learn more {background-image="images/image-from-rawpixel-id-8863371-original.jpg" background-opacity=0.3}

::: {.nonincremental}
-   Documentation at <https://vetiver.rstudio.com/>

-   [Webinar by Isabel Zimmerman and me](https://juliasilge.github.io/mlops-rstudio-meetup/) for Posit Enterprise Meetup

-   End-to-end demos from Posit Solution Engineering in [R](https://github.com/sol-eng/bike_predict) and [Python](https://github.com/sol-eng/bike_predict_python)
:::


## Thank you! {background-image="images/image-from-rawpixel-id-8863371-original.jpg" background-opacity=0.3}

<center>

<img src="https://github.com/juliasilge.png" style="border-radius: 50%;" width="300px"/>

[{{< fa brands github >}} \@juliasilge](https://github.com/juliasilge)

[{{< fa brands mastodon >}} \@juliasilge\@fosstodon.org](https://fosstodon.org/@juliasilge)

[{{< fa brands youtube >}} youtube.com/juliasilge](https://www.youtube.com/juliasilge)

[{{< fa link >}} juliasilge.com](https://juliasilge.com/)

</center>

::: footer
Image credits: [Mohammed Gadi](https://unsplash.com/photos/2qCX0SsSwzs), [Albert Edelfelt](https://www.rawpixel.com/image/8863371/image-art-public-domain-woman), [Bergen Public Libray](https://www.flickr.com/photos/bergen_public_library/sets/72157633827993925)
:::
